---
title: "workshop-code"
format: html
execute: 
  warning: false
  message: false
---

## Setup

```{r libraries}
library(tidyverse)
library(here)
library(lterdatasampler)
library(performance) # use to check performance of model (evaluate normality, heterostedasticity)
library(broom) # put all outputs from model into table
library(flextable)
library(ggeffects)
library(car)
library(naniar) # look at missing data
```

# Linear models

How does stem length _predict_ stem dry mass?

```{r filtering data}

maples_data <- hbr_maples %>% 
  
  # only include stuff from 2003 and Reference watershed
  filter(year == 2003 & watershed == "Reference")

```

Visualizing missing data:

```{r missing-data-vis}
gg_miss_var(maples_data)
```

Create an exploratory data visualization:

```{r explore-data-vis}

ggplot(data = maples_data, aes(x = stem_length, y = stem_dry_mass)) +
  geom_point()

```

Let's try a model:

```{r linear-model-maples}

maples_model <- lm(stem_dry_mass ~ stem_length, data = maples_data)

# intercept = 0.0070033; slope = 0.0001958
maples_model

```
Check assumptions:

1. linear relationship between variables: yes! (used the exploratory data visualization to check that)
2. independence of errors: yes! (making that assumption based on how data were collected)
3. homoskedasticity of errors: yes! (making that decision from residuals vs  fitted plot/scale-location plots)
4. normally distributed errors: yes! (looking at QQ plot of residuals)

```{r checking-assumptions}

# Write "plot(maples_model)" in console to get 4 diagnostic plots
# Plot 1: residuals vs fitted plot (checks for homoscedasticity of residuals)
# Plot 2: QQ plot (are residuals normally distributed?)
# Plot 3: scale-location plot (similar to plot 1 but square root of residuals)
# Plot 4: Residuals vs leverage plot (looks for outliers)

# makes the viewer pane show a 2x2 grid of plots
# format: par(mfrow = c(number of rows, number of columns))
par(mfrow = c(2,2))
plot(maples_model)

```

turn off the 2x2 grid:

```{r turning-off-the-grid, results = FALSE}

# dev.off()

```


# Putting things together to communicate

## model predictions

```{r pulling out predictions}

# ggpredict is from ggeffects package
predictions <- ggpredict(maples_model, terms = "stem_length") # terms = predictor variable

predictions
```
plot predictions

```{r plotting-predictions}

plot_predictions <- ggplot(data = maples_data, 
                           aes(x = stem_length, y = stem_dry_mass)) +
  
  # first plot the underlying data from maples_data
  geom_point() + 
  
  # then plot the predictions
  geom_line(data = predictions, 
            aes(x = x, y = predicted), 
            color = "blue", linewidth = 1) +
  
  # then plot the 95% confidence interval from ggpredict
  # alpha is making the ribbon more transparent
  geom_ribbon(data = predictions, 
              aes(x = x, y = predicted, ymin = conf.low, ymax = conf.high), 
              alpha = 0.2) +
  
  # theme and meaningful labels
  theme_bw() +
  labs(x = "Stem length (mm)",
       y = "Stem dry mass (g)")

plot_predictions

```

## create tables

```{r model-summary-table}

# store the model summary as an object
model_summary <- summary(maples_model)

# store the ANOVA table as an object
# anova(): special function to get analysis of variance tables for a model
model_squares <- anova(maples_model)

model_summary
```

making a table

```{r}

# tidy is a function in broom that pulls out stuff from anova table into dataframe
# can use this to communicate where the R2 value comes from (smth about ratio of sumsq)
model_squares_table <- tidy(model_squares) %>% 
  
  # for tiny p-values, just say it's less than 0.001 rather than showing the exact number
  mutate(p.value = case_when(
    p.value < 0.001 ~ "< 0.001")) %>% 
  
  # flextable makes it from dataframe to table
  flextable() %>% 
  
  # change header labels
  set_header_labels(df = "Degrees of freedom", 
                    sumsq = "Sum of squares")

model_squares_table

```







